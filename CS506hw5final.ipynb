{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b9a85b-3034-4d3b-bf49-fce9168f5c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1, Metric=euclidean, Weights=uniform, AUC=0.8472\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class CustomKNN:\n",
    "    def __init__(self, k=3, metric='euclidean', p=2, weight_type='uniform'):\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "        self.p = p\n",
    "        self.weight_type = weight_type\n",
    "\n",
    "    def fit(self, features, labels):\n",
    "        self.train_features = np.array(features)\n",
    "        self.train_labels = np.array(labels)\n",
    "\n",
    "    def calculate_distances(self, X):\n",
    "        if self.metric == 'euclidean':\n",
    "            return np.sqrt(((X[:, np.newaxis] - self.train_features) ** 2).sum(axis=2))\n",
    "        elif self.metric == 'manhattan':\n",
    "            return np.abs(X[:, np.newaxis] - self.train_features).sum(axis=2)\n",
    "        elif self.metric == 'minkowski':\n",
    "            return np.sum(np.abs(X[:, np.newaxis] - self.train_features) ** self.p, axis=2) ** (1 / self.p)\n",
    "        else:\n",
    "            raise ValueError(\"Distance metric not supported\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        distances = self.calculate_distances(X)\n",
    "        nearest_indices = np.argsort(distances, axis=1)[:, :self.k]\n",
    "        nearest_labels = self.train_labels[nearest_indices]\n",
    "        \n",
    "        if self.weight_type == 'uniform':\n",
    "            return np.mean(nearest_labels, axis=1)\n",
    "        elif self.weight_type == 'distance':\n",
    "            nearest_distances = np.take_along_axis(distances, nearest_indices, axis=1)\n",
    "            weights = 1 / (nearest_distances + 1e-5)\n",
    "            return np.sum(weights * nearest_labels, axis=1) / np.sum(weights, axis=1)\n",
    "\n",
    "def prepare_data(train_file, test_file):\n",
    "    train_df = pd.read_csv(train_file)\n",
    "    test_df = pd.read_csv(test_file)\n",
    "\n",
    "    target_train = train_df['Exited']\n",
    "    features_train = train_df.drop(['id', 'CustomerId', 'Surname', 'Exited'], axis=1)\n",
    "    features_test = test_df.drop(['id', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "    # Encoding categorical features\n",
    "    features_train['Geography'] = pd.factorize(features_train['Geography'])[0]\n",
    "    features_train['Gender'] = pd.factorize(features_train['Gender'])[0]\n",
    "\n",
    "    features_test['Geography'] = pd.factorize(features_test['Geography'])[0]\n",
    "    features_test['Gender'] = pd.factorize(features_test['Gender'])[0]\n",
    "\n",
    "    # Scaling numeric data\n",
    "    feature_means = features_train.mean()\n",
    "    feature_stds = features_train.std()\n",
    "\n",
    "    features_train = (features_train - feature_means) / feature_stds\n",
    "    features_test = (features_test - feature_means) / feature_stds\n",
    "\n",
    "    return features_train.values, target_train.values, features_test.values, test_df['id']\n",
    "\n",
    "def cross_validation(X, y, knn_model, splits=5):\n",
    "    n_samples = X.shape[0]\n",
    "    fold_size = n_samples // splits\n",
    "    auc_scores = []\n",
    "\n",
    "    for fold in range(splits):\n",
    "        val_start = fold * fold_size\n",
    "        val_end = (fold + 1) * fold_size if fold != splits - 1 else n_samples\n",
    "\n",
    "        X_train = np.concatenate((X[:val_start], X[val_end:]))\n",
    "        y_train = np.concatenate((y[:val_start], y[val_end:]))\n",
    "        X_val = X[val_start:val_end]\n",
    "        y_val = y[val_start:val_end]\n",
    "\n",
    "        knn_model.fit(X_train, y_train)\n",
    "        y_pred = knn_model.predict(X_val)\n",
    "\n",
    "        auc = np.mean((y_val == 1) * (y_pred >= 0.5) + (y_val == 0) * (y_pred < 0.5))\n",
    "        auc_scores.append(auc)\n",
    "\n",
    "    return np.mean(auc_scores), auc_scores\n",
    "\n",
    "def optimize_hyperparameters(X, y, X_test, test_ids, max_neighbors=20, auc_target=0.9):\n",
    "    best_k = 1\n",
    "    best_score = 0\n",
    "    best_metric = 'euclidean'\n",
    "    best_weight = 'uniform'\n",
    "    available_metrics = ['euclidean', 'manhattan']\n",
    "    weight_options = ['uniform', 'distance']\n",
    "\n",
    "    for metric in available_metrics:\n",
    "        for weight_type in weight_options:\n",
    "            for k in range(1, max_neighbors + 1):\n",
    "                knn = CustomKNN(k=k, metric=metric, weight_type=weight_type)\n",
    "                mean_auc, _ = cross_validation(X, y, knn)\n",
    "                print(f\"K={k}, Metric={metric}, Weights={weight_type}, AUC={mean_auc:.4f}\")\n",
    "                \n",
    "                if mean_auc > best_score:\n",
    "                    best_score = mean_auc\n",
    "                    best_k = k\n",
    "                    best_metric = metric\n",
    "                    best_weight = weight_type\n",
    "\n",
    "                if mean_auc >= auc_target:\n",
    "                    print(f\"Target AUC {auc_target} reached. Stopping and saving results.\")\n",
    "                    knn.fit(X, y)\n",
    "                    test_preds = knn.predict(X_test)\n",
    "                    pd.DataFrame({'id': test_ids, 'Exited': test_preds}).to_csv(f'results_k{k}_{metric}_{weight_type}.csv', index=False)\n",
    "                    return best_k, best_metric, best_weight, best_score\n",
    "\n",
    "    return best_k, best_metric, best_weight, best_score\n",
    "\n",
    "# Data preparation\n",
    "X_train, y_train, X_test, test_ids = prepare_data('train.csv', 'test.csv')\n",
    "\n",
    "# Hyperparameter tuning and output predictions\n",
    "best_k, best_metric, best_weight, best_auc = optimize_hyperparameters(X_train, y_train, X_test, test_ids)\n",
    "print(f\"Optimal K: {best_k}, Metric: {best_metric}, Weights: {best_weight}, Best AUC: {best_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4340f5de-e02a-44c8-bdd0-97e448808516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_submission(test_file, predictions, output_file='submission.csv'):\n",
    "    test_data = pd.read_csv(test_file)\n",
    "    submission = pd.DataFrame({\n",
    "        'id': test_data['id'],\n",
    "        'Exited': predictions\n",
    "    })\n",
    "    submission.to_csv(output_file, index=False)\n",
    "    print(f\"Predictions saved to '{output_file}'.\")\n",
    "\n",
    "# Call the function to save the predictions\n",
    "prepare_submission('submission.csv', test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0a5968-70f5-462c-9e02-a0b4e86e76b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
